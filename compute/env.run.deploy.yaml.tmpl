# Cloud Run env vars for goldmind-compute
# Use with:
#   gcloud run deploy goldmind-compute \
#     --image us-central1-docker.pkg.dev/$PROJECT_ID/goldmind/goldmind-compute:$TAG \
#     --region us-central1 --platform managed --allow-unauthenticated \
#     --env-vars-file env.run.deploy.yaml \
#     --cpu=1 --memory=2Gi --timeout=300
#
# NOTE: Do NOT set PORT here; Cloud Run sets it automatically.

SERVICE_NAME: "goldmind-compute"
LOG_LEVEL: "INFO"

# CORS (comma-separated)
CORS_ALLOW_ORIGINS: "https://fwgoldmindai.com,https://www.fwgoldmindai.com,https://app.fwgoldmindai.com,https://admin.fwgoldmindai.com,http://localhost:3000,http://localhost:5173"
CORS_ALLOW_METHODS: "GET,POST,OPTIONS"
CORS_ALLOW_HEADERS: "Accept,Content-Type,Authorization,X-Requested-With,X-Internal-Secret"

# Feature flags
HEALTH_ENABLE: "true"
PREDICT_ENABLE: "true"
BIAS_ENABLE: "false"
SETTINGS_ENABLE: "false"
VERSION_ENABLE: "true"

# Model loading
MODEL_PATH: "/app/lstm_models/SPY_lstm_model.h5"     # update if you use another file
SCALER_PATH: "/app/lstm_models/scalers.joblib"       # optional; leave if unused
MODEL_SHA256: ""                                     # optional integrity check

SEQ_LEN: "60"
FEATURES: "close"                                    # or "close,volume" if multivariate

# TensorFlow / threading
NUM_THREADS: "1"
TF_CPP_MIN_LOG_LEVEL: "2"

# Gunicorn tuning (used by Docker CMD)
GUNICORN_WORKERS: "1"
GUNICORN_THREADS: "8"
GUNICORN_TIMEOUT: "240"

# Inference knobs
INFERENCE_TIMEOUT_MS: "10000"
INFERENCE_BATCH_SIZE: "1"

# Rate limiting (simple in-process guardrail)
RATE_LIMIT_ENABLED: "true"
RATE_LIMIT_WINDOW_SECONDS: "60"
RATE_LIMIT_MAX_REQUESTS: "120"

# Presentation
JSONIFY_PRETTYPRINT: "false"
DISABLE_SERVER_SIGNATURE: "true"
